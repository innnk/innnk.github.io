---
layout: post
title: 西瓜书笔记（四）
tags: [机器学习, 读书笔记, 总结]
category: 技术
mathjax: true
---
>既然开始学习机器学习，那么肯定不能少了经典的西瓜书，作为入门经典教材，讲解的通俗易懂，而且较为系统。工作之余，我也决定读一遍西瓜书，可能大部分内容都有所了解了，这个系列的博客就再总结些自己认为重要的。

# 聚类
在无监督学习中，训练样本的lable是未知的，通过对无标记训练样本的学习来揭示数据的内在性质及规律。关于聚类的一个问题是聚类问题本身是病态的。这是说没有单一的标准去度量聚类的数据在真实世界中效果如何。我们可以度量聚类的性质，例如类中元素到类中心点的欧几里得距离的均值。这使我们可以判断从聚类分配中重建训练数据的效果如何。然而我们不知道聚类的性质是否很好地对应到真实世界的性质。假设我们在包含红色卡车图片、红色汽车图片、灰色卡车图片和灰色汽车图片的数据集上运行两个聚类算法。如果每个聚类算法聚两类，那么可能一个算法将汽车和卡车各聚一类，另一个根据红色和灰色各聚一类。假设我们还运行了第三个聚类算法，用来决定类别的数目。这有可能聚成了四类，红色卡车、红色汽车、灰色卡车和灰色汽车。现在这个新的聚类至少抓住了属性的信息，但是丢失了相似性信息。
## 性能度量
* 外部指标：将聚类结果与某个“参考模型”进行比较
* 内部指标：直接考察聚类结果而不利用任何参考模型

## 原型聚类

1. k-means
采用贪心策略，迭代。该算法提供了 k-维的 one-hot 编码向量 h 以表示输入 x。当 x 属于聚类 i 时，有$h_i=1$,h的其他项为零。

2. 学习向量量化（LVQ）
LVQ假设数据样本带有类别标记，学习过程中利用样本的这些监督信息来辅助聚类。给定样本（带标签的二元组），LVQ的目标是学得一组原型向量，每个原型向量代表一个聚类簇。在更新迭代的过程中，若原型向量与样本的类别相同，则原型向量向样本靠近（学习率），反之变远。

3. 高斯混合聚类
与Kmeans和LVQ用原型刻画聚类结构不同，高斯混合聚类采用概率模型来表达聚类原型。（EM算法）

## 密度聚类
此类算法假设聚类结构能通过样本分布的紧密成都确定。（DBSCAN）将“簇”定义为由密度可达关系导出的最大密度相连样本集合。算法先任选数据集中的一个核心对象为“种子”。
## 层次聚类
试图在不同层次上对数据集进行划分，从而形成树形的聚类结构，数据集的划分可采用“自底向上”的聚合策略，也可采用“自顶向下”的分拆策略。
AGNES是一种自底向上的聚合策略，先将数据集中的每个样本看作一个初始聚类簇，然后在下一步中找出距离最近的两个聚类簇进行合并，不断重复，直至达到预设的聚类簇个数，这里的关键是如何计算聚类簇之间的距离（最小距离由两个簇最近样本决定，最大由最远，平均则由所有样本共同决定）
## 无监督学习与监督学习
无监督算法只处理“特征”，不操作监督信号。监督和无监督算法之间的区别没有规范严格的定义，因为没有客观的判断来区分监督者提供的值是特征还是目标。通俗地说，无监督学习的大多数尝试是指从不需要人为注释的样本的分布中抽取信息。该术语通常与密度估计相关，学习从分布中采样、学习从分布中去噪、寻找数据分布的流形或是将数据中相关的样本聚类。