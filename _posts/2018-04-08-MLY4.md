---
layout: post
title: ML Yearning（16~20章）
tags: [机器学习, 读书笔记, 总结]
category: 技术
mathjax: true
---
>我的DL启蒙导师Andrew Ng（吴恩达）又出新书了，虽然是草稿，但完全免费（圈起来，要考）也实在太良心了！！！《九阴真经》订阅就送有木有！！。我是第一时间就订阅，每有新的更新就会直接收到邮件。目前收到了前几章，读取来感觉又是太良心了！！！全是工程实践的干货有木有！！对于项目经验欠缺的我来说，真实如获至宝。这个系列的博客我将分享自己读后笔记，欢迎订阅！

## 16.清理被错误标记的开发集和测试集样本
例如，也许一些不是猫的被标记成了猫，增加一个类别跟踪这部分标记错误地样本。
|图像|狗|大猫|模糊|误分类|备注|
|---|---|---|---|---|---|
|1|√|&nbsp;|&nbsp;|&nbsp;|不常见的美国比特犬|	
|2|&nbsp;|&nbsp;|√|&nbsp;|&nbsp;|
|...|...|...|...|...|...|	
|99|&nbsp;|&nbsp;|&nbsp;|√|没标记到猫|
|100|&nbsp;|&nbsp;|&nbsp;|√|画的猫，不是真猫|
|占全体比例|8%|43%|61%|6%|&nbsp;|
你应该在你的开发集中正确把这些错误标记的样本改过来吗？记住开发集的目的是帮助你快速地评估算法，那样你就能分辨算法A和B哪个更好。如果开发集错误标记的部分阻碍了你做这个判断，那么是值得花时间修改错误的标签。

例如假设你的分类器性能如下：

* 开发集的总体准确度……………90%（10%的总体错误率）
* 标记错误导致的误差……………0.6%（占开发集错误的6%）
* 其他导致的错误…………………9.4%（占开发集错误的94%）
由于标记错误导致的0.6%的错误率相比较你可以提升的9.4%的错误来说不够大。手动地修正开发集中的错误标签没有什么害处，但是这样做的意义不大。
## 17.将大型开发集拆分为两个子集，专注其一

假设有一个大开发集，误分类样本将会非常多，如果此时仍然逐个人工检查，成本过高。建议将开发集分为Eyeball集与blackbox集，顾名思义，前者是需要人工检查的样本集合，通过它可以找到改进方向；而blackbox则用于评价分类器和调整算法。
当你在 Eyeball 开发集中建立对样本的直观认识之后，则容易更快地过拟合。当你发现 Eyeball 开发集的性能比 Blackbox 开发集提升得更快，说明已经过拟合 Eyeball 开发集了。此时可能需要丢弃它并寻找一个新的 Eyeball 开发集，比如可以将更多 Blackbox 开发集中的样本移到 Eyeball 开发集中，也可以获取新的标注数据。
将开发集明确地分为 Eyeball 和 Blackbox 开发两个子集将很有帮助，它使你了解在人为的误差分析过程中 Eyeball 开发集何时开始发生过拟合。

## 18.Eyeball 和 Blackbox 开发集该设置多大？

* 尽量保证Eyeball开发集样本数量大于100，当然越大越好
* 一个有 1000-10000 个样本的 Blackbox 开发集通常会为你提供足够的数据去调超参和选择模型，即使数据再多一些也无妨。
* 如果开发集数量过小，那么尽量保证Eyeball集的大小

## 19.小结：基础误差分析

* 当你开始一个新项目，尤其是在一个你不擅长领域时，很难正确猜测出最有前景的方向。
* 所以，不要在一开始就试图设计和构建一个完美的系统。相反，应尽可能快（可能在短短几天内）地构建和训练一个基本系统。然后使用误差分析去帮助你识别出最有前景的方向，并据此不断迭代改进你的算法。
* 通过手动检查约 100 个算法错误分类的开发集样本来执行误差分析，并计算主要的错误类别。用这些信息来确定优先修正哪种类型的错误。
* 考虑将开发集分为人为检查的 Eyeball 开发集和非人为检查的 Blackbox 开发集。如果在 Eyeball 开发集上的性能比在 Blackbox 开发集上好很多，那么你已经过拟合 Eyeball 开发集，并且应该考虑为其获得更多的数据。
* Eyeball 开发集应该足够大，以便于算法有足够多的错误分类样本供你分析。对很多应用来说，含有1000-10000个样本的 Blackbox 开发集已足够。
* 如果你的开发集不够大到可以按照这种方式进行拆分，那么就使用 Eyeball 开发集来用于人工误差分析、模型选择和调超参。

## 20.偏差和方差：误差的两大来源

有更多的数据是无害的，然而它并不总是如我们期望的那样有帮助。假设你希望构建一个误差为 5% 的猫识别器。而目前的训练集错误率为 15%，开发集错误率为 16%。在这种情况下，添加数据可能不会有太多帮助。更应该改进算法，使他在训练集上表现更好。
开发集上16%的误差来源有两方面：

* 第一部分是算法在训练集上的错误率。在本例中，它是 15%。我们非正式地将它作为算法的偏差（bias）。

* 第二部分指的是算法在开发集（或测试集）上的表现比训练集上差多少。在本例中，开发集表现比训练集差 1%。我们非正式地将它作为算法的方差（variance）。
建立对偏差和方差的良好直觉将帮助你为算法选择有效的改变。

