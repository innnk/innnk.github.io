---
layout: post
title: 西瓜书笔记（一）
tags: [机器学习, 读书笔记, 总结]
category: 技术
mathjax: true
---
>既然开始学习机器学习，那么肯定不能少了经典的西瓜书，作为入门经典教材，讲解的通俗易懂，而且较为系统。工作之余，我也决定读一遍西瓜书，可能大部分内容都有所了解了，这个系列的博客就再总结些自己认为重要的。

# 第5章 神经网络
1. 感知机（全部为两层）无法解决线性不可分的问题，需要在中间加上隐含层。
2. 误差逆传播算法（BP）
* BP是一种迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计，基于梯度下降策略，以目标的负梯度方向对参数进行调整,通过链式法则找到待求解参数与。**注意：推导过程中用到了sigmoid函数的重要性质：**
$$f^{'}（x）=f(x)(1-f(x))$$
* BP算法的目标是最小化训练集上的累积误差，标准BP算法仅针对一个训练集的样本误差进行计算，参数更新非常频繁，设置对于不同训练集，更新效果可能出现“抵消”现象。累积BP算法在读取整个训练集后才进行参数更新，但在许多任务中，累积误差下降到一定程度后，进一步下降会很慢，此时使用标准BP效果更好。
* 防止过拟合：
   1. 早停：将数据分成训练集和验证集，若训练集误差降低但验证集误差升高，则停止训练；
   2. 正则化：在目标函数中增加描述网络复杂度的参数，希望得到更简单的网络结构。

3. 全局最小与局部极小
 * 取多组不同的初始值进行训练
 * 使用“模拟退火“算法，在每一步都以一定的概率接受比当前解更差的结果。
 * 使用随机梯度下降，即使陷入局部极值点，梯度也可能不为0，而跳出。